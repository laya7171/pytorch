{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqXxpvtp2Mm0qLuPG1R0X9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laya7171/pytorch/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4RkARMlqUNMg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/100_Unique_QA_Dataset.csv\")"
      ],
      "metadata": {
        "id": "KUkBaeIBZjKL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AsDz6Ru0Zm_1",
        "outputId": "c2b48a98-34b9-4111-aab4-ceafefedb731"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3b9910f-42d0-4a62-8181-2508a8c2b485\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b9910f-42d0-4a62-8181-2508a8c2b485')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3b9910f-42d0-4a62-8181-2508a8c2b485 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3b9910f-42d0-4a62-8181-2508a8c2b485');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-22092fe0-588e-4487-b656-375a677fb2e1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22092fe0-588e-4487-b656-375a677fb2e1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-22092fe0-588e-4487-b656-375a677fb2e1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower()  #preprocessing of the data\n",
        "  text = text.replace(\"?\", \"\") #removing the ?, ''\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "wAd5_bK3Zo2Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokenize(\"What is the capital of France?\")"
      ],
      "metadata": {
        "id": "JOilF-ylZ5eG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv0SSYDkZ8Fa",
        "outputId": "92a51831-8123-4f6f-f0a1-e010f60620c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<UNK>':0}"
      ],
      "metadata": {
        "id": "pZjSUm5maAGw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U1v8lqtgb5sz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_token = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_token:\n",
        "\n",
        "    if token != vocab:\n",
        "      vocab[token] = len(vocab)\n"
      ],
      "metadata": {
        "id": "5aNIKCWRarpj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lbWKIY7Ua1Ty",
        "outputId": "a67ee5e4-d7f4-4460-b11f-15039dde0aef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx7QBBQubBoU",
        "outputId": "fc338f9a-26cf-458a-efee-421576fd64f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 317,\n",
              " 'is': 322,\n",
              " 'the': 322,\n",
              " 'capital': 317,\n",
              " 'of': 320,\n",
              " 'france': 324,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 308,\n",
              " 'wrote': 189,\n",
              " 'to': 282,\n",
              " 'kill': 13,\n",
              " 'a': 301,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 168,\n",
              " 'planet': 281,\n",
              " 'in': 297,\n",
              " 'our': 20,\n",
              " 'solar': 130,\n",
              " 'system': 130,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 60,\n",
              " 'water': 134,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 130,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 245,\n",
              " 'root': 245,\n",
              " '64': 35,\n",
              " '8': 263,\n",
              " 'chemical': 161,\n",
              " 'symbol': 161,\n",
              " 'for': 322,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 322,\n",
              " 'year': 220,\n",
              " 'did': 44,\n",
              " 'world': 185,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 260,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 322,\n",
              " 'as': 319,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 260,\n",
              " 'united': 172,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 296,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 288,\n",
              " 'many': 288,\n",
              " 'continents': 80,\n",
              " 'are': 289,\n",
              " 'there': 82,\n",
              " 'on': 277,\n",
              " 'earth': 166,\n",
              " '7': 290,\n",
              " 'gas': 241,\n",
              " 'do': 241,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 185,\n",
              " 'prime': 271,\n",
              " 'number': 120,\n",
              " '2': 95,\n",
              " 'invented': 239,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 270,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 239,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 317,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 212,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 277,\n",
              " 'has': 301,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 279,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 236,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 322,\n",
              " 'famous': 269,\n",
              " 'sushi': 139,\n",
              " 'was': 270,\n",
              " 'first': 277,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 192,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 262,\n",
              " 'hexagon': 152,\n",
              " 'have': 263,\n",
              " '6': 154,\n",
              " 'china': 229,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 303,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 211,\n",
              " 'area': 212,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 269,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 283,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 275,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd_h7QfUd4d4",
        "outputId": "22013120-c0b9-41ed-bbf8-c1f065a7883b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert word to numerical values\n",
        "def text_to_indices(text, vocab):\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token]) #will return the text like [1,2,3]\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "7xLYIh_id5ZW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices(\"what is living stone?\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hbDUeVufEGa",
        "outputId": "c3cb4b5e-ce89-4601-fc8c-6d59352362ba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[317, 322, 222, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader , Dataset"
      ],
      "metadata": {
        "id": "6z822l8gfJET"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomData(Dataset):\n",
        "\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    numerical_question = text_to_indices(df.iloc[idx]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(df.iloc[idx]['answer'], self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "Oymb4OaDfx0J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomData(df, vocab)"
      ],
      "metadata": {
        "id": "CMn7fTBJgszQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnpUIaDYgykH",
        "outputId": "71f25d16-3321-4418-a03f-b3cc90a11c5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([317, 322, 322, 317, 320, 324]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "yU4cmv5Xgz8G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, answer in dataloader:\n",
        "  print(question, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_4dtRTJhAri",
        "outputId": "325323d5-43d1-46b4-f59d-551f573a057c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[317, 322, 322,  50,  51, 297, 322, 185]]) tensor([[52]])\n",
            "tensor([[322, 250, 251, 301, 252, 253]]) tensor([[254]])\n",
            "tensor([[322, 277, 301, 322, 119, 120, 120]]) tensor([[279]])\n",
            "tensor([[322, 281, 301, 322, 186, 187]]) tensor([[188]])\n",
            "tensor([[317, 322, 322, 161, 133, 320, 134]]) tensor([[134]])\n",
            "tensor([[317, 322, 322, 234, 320, 235]]) tensor([[236]])\n",
            "tensor([[322, 318, 322, 322, 319, 322, 319, 320, 320]]) tensor([[321]])\n",
            "tensor([[308, 130, 130, 236]]) tensor([[132]])\n",
            "tensor([[322, 241, 241, 241, 242, 297, 322, 243]]) tensor([[244]])\n",
            "tensor([[317, 322, 322, 317, 320, 260]]) tensor([[54]])\n",
            "tensor([[317, 322, 322, 317, 320,  73]]) tensor([[74]])\n",
            "tensor([[322, 220,  44, 185,  46,  47,  48]]) tensor([[49]])\n",
            "tensor([[308, 322, 322, 319, 322, 283, 320, 284]]) tensor([[285]])\n",
            "tensor([[308, 130, 322,  30,  31]]) tensor([[32]])\n",
            "tensor([[322, 290, 291, 301, 292, 303, 293, 294]]) tensor([[295]])\n",
            "tensor([[317, 322, 322, 260, 320, 229]]) tensor([[156]])\n",
            "tensor([[322, 322, 301, 322, 247, 320, 248]]) tensor([[249]])\n",
            "tensor([[317, 322, 322, 212, 320, 301, 213, 214]]) tensor([[215]])\n",
            "tensor([[322, 299, 300, 301, 301, 301, 302, 303, 303, 304, 305, 306]]) tensor([[307]])\n",
            "tensor([[288, 288, 261, 262, 301, 262, 263]]) tensor([[263]])\n",
            "tensor([[322, 322, 322, 210, 322, 211, 275, 212]]) tensor([[212]])\n",
            "tensor([[317, 322, 322, 260, 320, 260]]) tensor([[260]])\n",
            "tensor([[322, 125, 322, 322, 319, 322, 126, 127]]) tensor([[128]])\n",
            "tensor([[322, 107, 322, 108, 297, 317]]) tensor([[110]])\n",
            "tensor([[317, 322, 322, 317, 320, 212]]) tensor([[114]])\n",
            "tensor([[317, 322, 322, 317, 320, 236, 237]]) tensor([[238]])\n",
            "tensor([[317, 322, 322, 221, 320, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[308, 189, 282,  13, 301,  15]]) tensor([[16]])\n",
            "tensor([[317, 322, 322, 185, 322, 297, 322, 185]]) tensor([[185]])\n",
            "tensor([[317, 322, 322, 163, 164, 165, 277, 166]]) tensor([[166]])\n",
            "tensor([[308, 296, 322, 296, 297, 297]]) tensor([[298]])\n",
            "tensor([[308, 270, 322, 277, 142, 282, 143, 277, 322, 144]]) tensor([[145]])\n",
            "tensor([[317, 322, 322, 161, 161, 322, 161]]) tensor([[162]])\n",
            "tensor([[322, 281, 322, 322, 319, 322,  64, 281]]) tensor([[65]])\n",
            "tensor([[317, 322, 322, 277, 277, 277, 322, 277, 278]]) tensor([[279]])\n",
            "tensor([[322, 312, 322, 313, 322, 319, 322, 314, 315]]) tensor([[316]])\n",
            "tensor([[317, 322, 322, 317, 320, 135]]) tensor([[136]])\n",
            "tensor([[322, 241, 241,  88,  89, 322,  90]]) tensor([[91]])\n",
            "tensor([[288, 288, 150, 262, 301, 152, 263]]) tensor([[154]])\n",
            "tensor([[308, 189, 189, 303, 190]]) tensor([[191]])\n",
            "tensor([[288, 288, 195, 289, 297, 322, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[322, 322, 322, 269, 322, 139]]) tensor([[260]])\n",
            "tensor([[317, 322, 322, 260, 320, 322, 172,  71]]) tensor([[72]])\n",
            "tensor([[317, 322, 322, 245, 245, 320, 245]]) tensor([[246]])\n",
            "tensor([[308,  55, 322,  56, 320,  57]]) tensor([[58]])\n",
            "tensor([[322, 216, 301, 217, 218, 297, 301, 219, 220]]) tensor([[220]])\n",
            "tensor([[317, 322, 322, 317, 320, 286]]) tensor([[287]])\n",
            "tensor([[317, 322, 322, 161, 161, 322,  40]]) tensor([[41]])\n",
            "tensor([[322, 322, 322, 226, 282, 322, 227, 228]]) tensor([[229]])\n",
            "tensor([[322, 167, 322, 322, 168, 211, 212]]) tensor([[170]])\n",
            "tensor([[317, 322, 322, 317, 320, 206]]) tensor([[207]])\n",
            "tensor([[317, 322, 322, 245, 245, 320,  35]]) tensor([[263]])\n",
            "tensor([[308, 296, 208]]) tensor([[209]])\n",
            "tensor([[322, 101, 322, 322, 168]]) tensor([[102]])\n",
            "tensor([[317, 322, 322, 317, 320, 270]]) tensor([[100]])\n",
            "tensor([[317, 322, 322, 103, 320, 239, 297, 105]]) tensor([[106]])\n",
            "tensor([[317, 322, 322,  59,  60, 320, 134, 297,  60]]) tensor([[61]])\n",
            "tensor([[288, 288,  80, 289,  82, 277, 166]]) tensor([[290]])\n",
            "tensor([[322, 263, 264, 301, 265, 266, 303, 267]]) tensor([[268]])\n",
            "tensor([[308, 239, 322,  97]]) tensor([[98]])\n",
            "tensor([[317, 322, 322, 192, 147, 297, 148]]) tensor([[149]])\n",
            "tensor([[308, 296, 111]]) tensor([[112]])\n",
            "tensor([[322, 322, 322, 322, 322, 322, 322, 323]]) tensor([[324]])\n",
            "tensor([[322, 255, 322, 256, 277, 257, 258]]) tensor([[259]])\n",
            "tensor([[317, 322, 322, 168, 281, 297,  20, 130, 130]]) tensor([[23]])\n",
            "tensor([[317, 322, 322, 317, 320, 279]]) tensor([[280]])\n",
            "tensor([[308, 270, 322, 277, 270, 271, 271, 320, 322, 272]]) tensor([[273]])\n",
            "tensor([[322, 322, 322, 274, 275, 275]]) tensor([[276]])\n",
            "tensor([[317, 322, 322, 185, 271, 120]]) tensor([[95]])\n",
            "tensor([[317, 322, 322, 317, 320, 317]]) tensor([[317]])\n",
            "tensor([[288, 288, 288, 289, 297, 301, 289]]) tensor([[290]])\n",
            "tensor([[308, 322, 322,  66, 320,  67]]) tensor([[68]])\n",
            "tensor([[317, 322, 322, 168, 115, 277, 166]]) tensor([[116]])\n",
            "tensor([[317, 322, 322, 317, 320, 324]]) tensor([[7]])\n",
            "tensor([[308, 296,  76]]) tensor([[77]])\n",
            "tensor([[317, 241, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[322, 200, 322, 301, 201, 202, 203, 204]]) tensor([[283]])\n",
            "tensor([[317, 322, 322, 317, 320,   8]]) tensor([[9]])\n",
            "tensor([[288, 288, 129, 289, 297, 322, 130, 130]]) tensor([[263]])\n",
            "tensor([[317, 322, 322, 122, 123, 297, 322, 185]]) tensor([[124]])\n",
            "tensor([[317, 322, 322,  24,  60, 320, 134, 297,  27]]) tensor([[28]])\n",
            "tensor([[308, 308, 322, 309, 310]]) tensor([[311]])\n",
            "tensor([[317, 322, 322, 192, 241, 297, 192, 193]]) tensor([[194]])\n",
            "tensor([[308, 189, 157, 303, 159]]) tensor([[160]])\n",
            "tensor([[322, 174, 322, 322, 322, 269, 176, 282, 177, 178]]) tensor([[179]])\n",
            "tensor([[322, 322, 322, 269, 322, 269, 269]]) tensor([[270]])\n",
            "tensor([[308, 270, 322, 277, 171, 320, 322, 172, 172]]) tensor([[173]])\n",
            "tensor([[322, 281, 322, 322, 281, 282, 322, 282]]) tensor([[283]])\n",
            "tensor([[308, 239, 322, 239, 239]]) tensor([[240]])\n",
            "tensor([[317, 322, 322, 180, 181, 182, 183]]) tensor([[184]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "WvV43fqehEce"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.embedding(x)\n",
        "    hidden, final = self.embedding(x)\n",
        "    output = self.fc(final)\n",
        "    return output"
      ],
      "metadata": {
        "id": "r9tKST5WDgz2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "N6dblwKRLWQd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(len(vocab))"
      ],
      "metadata": {
        "id": "_IvIU3OqLZHp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "u6L7Uy0OLbqJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(question)\n",
        "\n",
        "    loss = criteria(output, answer)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, total loss {total_loss:4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "b7_VhmzPL9ya",
        "outputId": "009f1cb9-8033-4f4c-82d4-305797bdb083"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3917456534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3909706534.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SX5JueUMoUP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}